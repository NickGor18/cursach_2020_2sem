\usepackage[cp1251]{inputenc}
\chapter{ОСНОВНЫЕ ПОНЯТИЯ И ОБЗОР ЛИТЕРАТУРЫ}\label{chap1}

\section{Теория управления по прогнозирующей модели}\label{MPC}
\normalsize{Управление по прогнозируемой модели (далее MPC, от англ. "Model Predictive Control") - это продвинутый метод управления процессами, который используется для соответствующего набора ограничений. Оно используется в перерабатывающей индустрии, на химических заводах и нефтепереработке с 80-х годов ХХ-го века. Сейчас данный метод так же используется при калибровке энергетических систем и силовой электронике. В МРС в основном используются динамические модели процессов, наиболее часто - линейные эмпирические. Главным приимуществом MPC является то, что он способен оптимизировать текущий временной отрезок, учитывая будущие интервалы. \\
\hspace{2cm}	Модели, используемые в MPC, направлены на то, чтобы отражать поведение сложных динамических систем. Они предсказывают изменения в зависимых переменных моделируемых систем благодаря изменениям независимых переменных. Например если речь идет о химических процессах, независимые переменные, которые могут быть добавлены регулятором чаще всего являются либо установками ПИД-регуляторов, либо конечными контрольными элементами.\\
	
\hspace{2cm} В основе MPC лежит итеративная конечногоризонтальная оптимизация модели производства. В момент времени $t$ производится выборка текущего состояния производства и вычисляется стратегия управления минимизацией затрат (с помощью алгоритма численной минимизации) для относительно короткого временного горизонта в будущем: $[t,t+T]$. В частности, онлайн-расчет или расчет «на лету» используются для изучения траекторий состояния, которые исходят из текущего состояния, и находят (посредством решения задач оптимального управления) стратегию минимизации затрат до времени $t+T$.\\
\hspace{2cm}	Реализуется только первый шаг стратегии управления, затем снова производится выборка состояния производства, и вычисления повторяются, начиная с нового текущего состояния, получая новый элемент управления и новый прогнозируемый путь состояния. Горизонт прогнозирования продолжает смещаться вперед, и по этой причине MPC также называют сдвигающимся горизонтом управления(англ. $ " $Receding horizon control$ " $).\\
\hspace{2cm} Хотя этот подход не является оптимальным, на практике он дал очень хорошие результаты. Было сделано много научных исследований, чтобы найти быстрые методы решения задач оптимального управления, понять глобальные свойства устойчивости локальной оптимизации MPC и в целом улучшить метод MPC.
	
}
\paragraph{Основные принципы MPC}
\normalsize{
	Управление по прогнозирующей модели это многомерный управляющий алгоритм, который использует: 
	\begin{itemize}
		\item  внутреннюю динамическую модель процесса;
		\item функцию затрат $ J $ над сдвигающимся горизонтом;
		\item алгоритм оптимизации, минимизирующий функцию стоимости $J$ с использованием управления $ u  $;
	\end{itemize}
	Примером для нелинейной функции стоимости для оптимизации может служить следующее уравнение 
	\begin{center}
		$J = \sum_{i=1}^{N}\omega_{x_i} (r_i - x_i)^2 + \sum_{i=1}^{N}\omega_{u_i}\bigtriangleup {u_i}^2$
	\end{center}
	не нарушая установленных ограичений утверждаем, что:
	\begin{flushleft}
		$x_i: i-$тая контролируемая переменная \\
		$r_i: i-$тая эталонная переменная \\
		$u_i: i-$тая изменяемая переменная \\
		$\omega_{x_i}-$коэффицент, отражающий важность $x_i$\\
		$\omega_{u_i}-$коэффицент, тормозящий относительно большие изменения в $u_i$\\
	\end{flushleft}
\hspace{2cm} Из приведенного краткого обзора методов MPC понятно, что их основу составляет решение задач оптимального управления на сдвигающемся горизонте управления с изменяющимся начальным состоянием. Поэтому в следующем разделе опишем основные результаты теории управления.
}
\section{Задачи оптимального управления}\label{MPC}
\normalsize{Задачи оптимального управления относятся к теории экстремальных задач, то есть задач определения максимальных и минимальных значений. Задачи эти, как и собственно сама теория оптимального управления, возникла в начале ХХ-го века в связи с практическими задачами, появившимися изза развития новой техники в различных областях. Данные экстремальные задачи не укладывались в рамки классического вариационного счисления. В данной главе рассмотрим их, используя различные примеры. В целом решение подобных задач можно разбить на два этапа: 
	\begin{enumerate}
		\item Постановка задачи 
		\item Решение с использованием условий оптимальности 
	\end{enumerate}
}
\paragraph{Постановка задачи }
\hfill \break
\normalsize{Изначально есть некоторое, условие, однако его недостаточно для решения задачи. Для начала проведем математическую постановку задачи. Она в себя будет включать следующие факторы: математическую модель объекта управления, цель управления, ограничения на траекторию воздействия, управляющее воздействие и его длительность и т.д. Рассмотрим данные факторы подробнее.
}\\
\paragraph{Модели объекта }
\hfill \break
\normalsize{Построение модели зависит от типа рассматриваемой задачи и того, что необходимо в итоге получить. Могут быть использованы различные дифференциальные уравнения: обыкновенные дифференциальные уравнения, уравнения с последействием, стохастические уравнения, уравнения в частных производных и т.д. Для примера будем использовать обыкновенное дифференциальное уравнение:
 }\\
\begin{flushright}
	\normalsize{ $\dot x(t) = f(t,x(t),u),\dot x(t)=dx/dt, t_0 \le t \le T $ \hspace{4cm} (1.1)}
\end{flushright}
\normalsize{$u \in \mathbb{R}^m-$управление, $x \in \mathbb{R}^n$-фазовый вектор системы, $f \in \mathbb{R}^n$-заданная функция. Придавая управлению различные значения мы получаем различные состояния объекта, из которых мы и выбираем оптимальное.}
\paragraph{Критерий качества}
\hfill \break
\normalsize{Управление системой (1.1) осуществляется для достижениянекоторыхцелей,которыеформальнозаписываютсявтерминахминимизации по u функционалов J, определяемых управлением u и траекторией х, где 
	\begin{flushright}
		$J= \int_{t_0}^{T}F(t,x(t),u)dt+ \varphi (T,x(T)) \rightarrow \min$\hspace{4cm}(1.2)
	\end{flushright} 
	F и $\varphi$ - заданные скалярные функции. Задача (1.2) в общем виде называется задачей Больца. При $F$ = 0 её называют задачей Майера, а при $\varphi$ = 0 - Лагранжа.}
\paragraph{Ограничения на траекторию и ограничения на управление}
\normalsize{Иногда траектория не может принадлежать какой-либо части пространства $\mathbb{R}^n$. В таких случаях указывают, что $x(t) \in G(t)$, при том, что $G(t)$-заданная область в $\mathbb{R}^n$. В зависимости от типа ограничений выделяют различные классы задач управления, такие как задачи с фиксированными концами, свободным левым либо правым концом. Так же существуют задачи с подвижными концами. Иногда же ограничения имеют интегральный характер и выглядят следующим образом: :
	\begin{center}
		$J = \int_{t_0}^{T} F(t,x(t),u)dt \le 0$
	\end{center}
}
\normalsize{Если в задачах (1.1),(1.2) начальное и конечное положение задано, моменты начала и конца движения свободны, функция  $\varphi = 0$, а $F = 1$,  то получаем задачу о переводе системы (1.1) из начального положения в конечное за минимально возможное время. Так же стоит упомянуть ограничения на управление, которые могут быть двух типов: 
	\begin{itemize}
		\item Информационные
		\item Ограниченность ресурсов управления 
	\end{itemize}
	%?????????????? ??????????? ?? ?????????? ??????? ?? ????, ????? ?????? ?????????? ? ??????? (1) ???????? ??? ????????? ???????????? ???????????. ???? ?????? $x(t)$ ?????????? ?????????, ?? ??????????? ?????????? ?????? ? ?????? ??????? $u(t)$, ????????? ?????? ?? $t$. ? ???? ?????? ??????????? ?????????? ?????????? ???????????. ???? ?? ?????? $x(t)$ ???????? ?????, ?? ??????????? ?????????? ?????????? ???????? ???????????? ?????????? ? ?????? ? ?????? ???????????? $u(t,x_{t_0}^{t}).$ ????? $x_{t_0}^{t}$ ? ??? ?????????? ???????? ?? ??????? $t_0 \le s \le t$.
	%???????????, ????????????? ??????????????? ???????? ?????????? ????? ??? $u(t) \in U(t)$,??? $U(t)$  ???????? ????????? ?? $R^m$.
}
\paragraph{Условия оптимальности}
\paragraph{Принцип максимума Понтрягина}
Рассмотрим простейшую задачу оптимального управления — задачу терминального управления \\
\begin{flushright}
	$ J(u) = \varphi(x(t_f)) \rightarrow \min $ \hspace{5cm}(1.3)\\
	$ \dot{x}(t) = f(x(t),u(t),t),x(t_0) = x_0 $ \hspace{4cm}(1.4)\\
	$ u(t) \in U,t \in [t_0,t_f].$ \hspace{5cm}(1.5)\\
\end{flushright}
Требуется минимизировать критерий качества (1.3) на траекториях системы (1.4) с помощью ограниченных управлений (1.5). \\
В задаче (1.3)–(1.5) моменты $ t_0, t_f $ заданы, $ x(t) \in \mathbb{R}^n  $— состояние системы управления в момент времени $ t;$ $ u(t) \in \mathbb{R}^r  $ значение управления в момент времени $ t $. \\
Относительно функций $ \varphi : \mathbb{R}^n \rightarrow \mathbb{R}$ и $ f:\mathbb{R}^n \times \mathbb{R}^r \times \mathbb{R} \rightarrow \mathbb{R}^n $  предположим, что они имеют частные производные $ \partial f(x,u,t) /\partial x, \partial \varphi (x)/\partial x$ и непрерывны вместе с этими производными по совокупности своих аргументов. \\
Задачу (1.3)–(1.5) будем рассматривать в классе кусочно-непрерывных управлений, удовлетворяющих условию (1.5) во всех точках непрерывности. Множество $ U \subset \mathbb{R}^r $— множество доступных значений управления, не зависит от времени. Предполагается, что $ U $ — компакт. \\
Отметим, что в задаче (1.3)–(1.5) левый конец траектории $ x(t_0) $ закреплен, правый $ x(t_f) $ — свободен, фазовые ограничения на траекторию $ x(\cdot) $ отсутствуют. Требуется минимизировать функцию терминального состояния — критерий типа Майера.\\
Принципом максимума называется основное необходимое условие оптимальности в задачах оптимального управления, связанное с максимизацией гамильтониана. \\
Принцип максимума был сформулирован как гипотеза в 1956г. группой советских математиков во главе с Л.С. Понтрягиным. Первые доказательства получены Р.В.Гамкрелидзе (1957) для линейных систем быстродействия и В.Г.Болтянским (1958) для общей ЗОУ. \\
Для формулировки принципа максимума введем гамильтониан:\\
\begin{flushright}
	$ H(x,\psi ,u,t)=\psi'f(x,u,t)=\sum_{j=1}^{n}\psi_j f_j (x,u,t) $ \hspace{4cm}(1.6)
\end{flushright}
Здесь $ \psi = \psi (t) \in \mathbb{R}^n $  — вспомогательные переменные, называемые сопряженной траекторией (котраекторией). \\
Для каждой пары $ (u(\cdot),x(\cdot)) $, состоящей из допустимого управления и соответствующей ему траектории, функцию $\psi (\cdot) = (\psi (t),t \in T) $ определим как решение сопряженного уравнения \\
\begin{flushright}
	$ \dot{\psi}(t) = -\dfrac{\partial H}{\partial x} (x(t),\psi(t),u(t),t) =-\dfrac{\partial f}{\partial x}(x(t),u(t),t)'\psi(t)$ \hspace{2cm}(1.7)
\end{flushright}
\begin{center}
	$ \dot{\psi_j}(t)=-\dfrac{\partial H}{\partial x_j}(x(t),\psi(t),u(t),t)=-\sum_{i=1}^{n}\psi_i(t)\dfrac{\partial f_i}{\partial x_j}(x(t),u(t),t), j=1,...,n $
\end{center}
с начальным условием на правом конце 
\begin{flushright}
	$ \psi(t_f)=-\dfrac{\partial \varphi}{\partial x}(x(t_f))$ \hspace{5cm}(1.8)
\end{flushright}
Здесь $ \frac{\partial f}{\partial x} $ - матрица всевозможных частных производных по $ x $, и всюду запись вида $ \dfrac{\partial H}{\partial x} (x(t),\psi(t),u(t),t) $ ),как это обычно принято, означает, что сначала вычисляется соответствующая частная производная функции $ H(x, \psi, u, t) $, а затем вместо аргументов подставляются их конкретные значения. \\
Условие (1.8) на правом конце $ \psi(t_f) $ сопряженной траектории часто называют условием трансверсальности. \\
Отметим, что сопряженное уравнение (1.7) линейно. 
С использованием гамильтониана уравнения (1.4), (1.7) могут быть представлены в виде системы Гамильтона: 
\begin{center}
	$ \dot{x}(t)=\dfrac{\partial H}{\partial x} (x(t),\psi(t),u(t),t) $\\
	$\dot{\psi}(t)=-\dfrac{\partial H}{\partial x} (x(t),\psi(t),u(t),t)$
\end{center}
Теперь можем сформулировать основной результат: \\
\textbf{Теорема: }(Принцип максимума Понтрягина). Пусть $ u^0(\cdot) $ - оптимальное управление в задаче (1.3)-(1.5), $ x^0(\cdot) $ -  соответствующая (оптимальная) траектория системы (1.4), $ \psi^0(\cdot) $ - соответствующее решение сопряженной системы 
\begin{center}
	$ \dot{\psi^0}(t) =  -\dfrac{\partial H}{\partial x} (x^0(t),\psi^0(t),u^0(t),t), \psi^0(t_f)=-\dfrac{\partial \varphi}{\partial x}(x^0 (t_f)),$
\end{center}
Тогда на оптимальном управлении $ u^0(\cdot) $  необходимо выполняется условие максимума гамильтониана 
\begin{center}
$ H(x^0(t), \psi^0(t), u^0(t), t) = \underset{\upsilon \in U}{max} H(x^0(t), \psi^0(t), \upsilon, t)$
\end{center}
для всех $ t \in [t_0,t_f]  $ являющихся точками непрерывности оптимального управления $ u^0(\cdot) $. 
\paragraph{Метод динамического программирования}
Применяя метод динамического программирования, изучают все поле оптимальных траекторий. Для того, чтобы сравнение было наглядным, воспользуемся ранее заданной задачей (1.3)-(1.5).\\
 \hspace{2cm} Зафиксируем некоторый произвольный момент времени $t \in [t_0,T]$. Рассмотрим вспомогательную задачу управления на отрезке $[t ,T]$. Через $V(t,x)$ обозначим минимальное значение критерия качества во вспомогательной задаче при начальном условии $x(t) = x$, где $x$ – произвольный вектор из $\mathbb{R}^n$. При некоторых предположениях функция $V(t,x)$ удовлетворяет соотношениям:
\begin{center}
	$\partial V(t,x)/\partial t+\underset{u \in U}{\min}f^{'} (t,x,u)  \partial V(t,x)/\partial x=0, $
\end{center}
\begin{flushright}
	$t_0\le t\le T,x\in \mathbb{R}^n,$ \hspace{5cm}                                (1.9)
\end{flushright}
\begin{center}
	$V(T,x)=F(x).$
\end{center}
Решив данную задачу и определив $V(t,x)$ мы можем найти управление $u(t,x)$ из соотношения:
\begin{flushright}
	$\underset{u \in U}{\min}f^{'}(t,x,u)  \partial V(t,x)/\partial x=f^{'}(t,x,u(t,x))  \partial V(t,x)/\partial x$ \hspace{1cm}       (1.10)
\end{flushright}
Возможность находить конкретно управление есть характерная черта метода динамического программирования. Она становится особенно важной в условиях отсутствия полной информации. При решении конкретных задач с помощью метода динамического программирования мы решаем нелинейное уравнение в частных производных (1.9), а так же дополнительно исследуем оптимальное управление, получаемое из уравнения (1.10).
\section{Численные и программные методы решения ЗОУ}
\paragraph{Численные методы}
Здесь будем говорить о четырех численных методах решения задач оптимального управления. 
\begin{itemize}
	\item Метод проекции градиента 
	\item Метод сопряженного градиента 
	\item Метод Ньютона 
	\item Метод штрафных функций 
\end{itemize}
Рассматривать каждый метод мы не будем, а сфокусируемся исключительно на первом

\subparagraph{Метод проекции градиента}
Опишем алгоритм решения для задачи  $f(x) \rightarrow \min$,  $ x \in X \subset \mathbb{R}^n$, где $f(x)$ - непрерывно дифференцируема, а множество $X$ выпукло, замкнуто и ограничено. Пусть задано начальное приближение $x^0 \in X$ и методом проекции градиента вычислено $x^k \in X$.  Следующее приближение вычисляем по формуле 
\begin{flushright}
	$x^{k+1}=P_X(x^k-\alpha_k\bigtriangledown f(x^k)), \alpha_k > 0,k=0,1,... \hspace{4cm}(1)$
\end{flushright} 
Сам же алгоритм метода проекции градиента основывается на следующих трех теоремах.\\
\textbf{Теорема 1.} Пусть точка $x^*$ есть точка локального минимума функции $f(x)$ на множестве $X$. Функция $f(X)$ предполагается непрерывно дифференцируемой, а множество $X$ выпуклым и замкнутым. Тогда для произвольного $\alpha \ge 0$ справедливо равенство 
\begin{center}
	$x^*=P_X(x^*-\alpha \bigtriangledown f(x^*)).$
\end{center}
\textbf{Теорема 2.} Пусть функция $f(x)$ является выпуклой, непрерывно дифференцируемой, множество $X$ выпуклым и замкнутым. Точка  $x^*$ есть точка локального минимума тогда и только тогда, когда для произвольного $\alpha >0$ справедливо равенство
\begin{center}
	$x^*=P_X(x^*-\alpha \bigtriangledown f(x^*)).$
\end{center}
В следующей теореме формулируются условия сходимости метода проекции градиента.\\
\textbf{Теорема 3.} Пусть в задаче $f(x) \rightarrow \min$, $x \in X \subset R^n$ функция $f(x)$ непрерывно дифференцируема, ограничена снизу, и на множестве $X$ её градиент удовлетворяет векторному условиб Липшица с константой $L$, то есть
\begin{center}
	$\|\bigtriangledown f(x + \bigtriangleup x) - \bigtriangledown f(x)\| \le L\|\bigtriangleup x\|  x, x + \bigtriangleup x \in X.$
\end{center}
Тогда при любом начальном приближении $x^0$ имеет место соотношение 
\begin{center}
	$\overset{k\rightarrow \infty}{\lim}\|x^{k+1}-x^{k}\|=0$
\end{center}
Если дополнительно предположить, что множество 
\begin{center}
	$M(x^0)=\{x\in \mathbb{R}^n |f(x)\le f(x^0)\}$
\end{center}
ограничено, то последовательность $\{x^k\}$ сходится к непустому множеству $S_* = \{x|x\in M(x^0),(\bigtriangledown f(x),y-x)\ge 0$ при всех $y \in X\}$ стационарных точек.\\
На основе данных трех теорем мы решаем задачи методом проекции градиента
\paragraph{Программные системы}

Сложная программная система, в частности, пакет для решения задач оптимального управления, имеет свое поле эффективной работы, которое, как правило, характеризуется классом решаемых системой задач и арсеналом применяемых ею методов. Однако структурные особенности программной системы, взаимосвязь и соответствие приближенных методов, применяемых на разных этапах поиска численного решения, а также способность системы самостоятельно конструировать путь поиска решения в зависимости от выявленных особенностей решаемой задачи выгодно отличают программную систему от теоретически описанного класса задач и набора методов для поиска их решения. Иерархическая структура вычислительной схемы и соответствующая композиция методов, применяемых на всех уровнях поиска численного решения, являются основными характеристиками эффективной программной системы. Программная система с хорошим уровнем интеллекта кроме широкого спектра методов, как правило, содержит много различных эвристик и логических алгоритмов для анализа сложившихся ситуаций, которые позволяют продолжить поиск оптимального управления и даже при прекращении сходимости какого-то метода. В этом случае может произойти переход либо к другому методу, либо – к подпрограмме, которая с помощью двойственного метода
вычислит оптимальную оценку невязки выполнения условий оптимальности. Для дальнейшей оптимизации программа может выбрать более подходящий алгоритм или, как, например, в задачах линейного программирования, перейти к обновлению базиса, чтобы избавиться от ошибок округления, накопившихся в ходе выполнения большого количества итераций\\